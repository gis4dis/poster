{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import django\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from apps.processing.ala.models import SamplingFeature, Observation\n",
    "from apps.processing.ala.util import util\n",
    "\n",
    "from importlib import import_module\n",
    "from django.conf import settings\n",
    "from apps.common.models import Process, Property\n",
    "\n",
    "import pytz\n",
    "import time\n",
    "from psycopg2.extras import DateTimeTZRange\n",
    "from django.utils.dateparse import parse_datetime\n",
    "from dateutil.parser import parse\n",
    "# from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "# from luminol.anomaly_detector import AnomalyDetector\n",
    "import luminol.anomaly_detector as lad\n",
    "\n",
    "from apps.utils.time import UTC_P0100\n",
    "from apps.common.util.util import generate_intervals\n",
    "# from apps.ad.anomaly_detection import *\n",
    "import apps.ad.anomaly_detection as ad\n",
    "\n",
    "feature = SamplingFeature.objects.get(id_by_provider='11359201')\n",
    "observed_property = Property.objects.get(name_id='air_temperature')\n",
    "\n",
    "from apps.mc.api.views import get_observations, parse_date_range, get_empty_slots, get_not_null_ranges, get_feature_nn_from_list\n",
    "\n",
    "from apps.processing.ala.models import SamplingFeature, Observation\n",
    "from apps.common.models import Process, Property, TimeSlots\n",
    "from psycopg2.extras import DateTimeTZRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic = \"drought\"\n",
    "prop = \"air_temperature\"\n",
    "phenomenon_date_from = pd.to_datetime(\"2019-01-01\")\n",
    "phenomenon_date_to = pd.to_datetime(\"2019-01-30\")\n",
    "provider_model = Observation\n",
    "features = provider_model._meta.get_field('feature_of_interest').remote_field.model.objects.all()\n",
    "\n",
    "def detect_anomalies(\n",
    "    phenomenon_date_from = phenomenon_date_from,\n",
    "    phenomenon_date_to = phenomenon_date_to,\n",
    "    detector_method='bitmap_mod',\n",
    "    use_baseline=True,\n",
    "    shift=True,\n",
    "    extend_range=True,\n",
    "    detector_params={\n",
    "        \"precision\": 6,\n",
    "        \"lag_window_size\": 96,\n",
    "        \"future_window_size\": 96,\n",
    "        \"chunk_size\": 2\n",
    "    },\n",
    "    topic = topic,\n",
    "    prop = prop,\n",
    "    provider_model = provider_model,\n",
    "    feature = features[0]\n",
    "):\n",
    "    reload(ad)\n",
    "    reload(lad)\n",
    "\n",
    "#     item = provider_model._meta.get_field('feature_of_interest').remote_field.model.objects.all()[0]\n",
    "\n",
    "    observation_provider_name = f\"{provider_model.__module__}.{provider_model.__name__}\"\n",
    "    topic_config = settings.APPLICATION_MC.TOPICS.get(topic)\n",
    "\n",
    "    properties = topic_config['properties']\n",
    "    ts_id = topic_config['time_slots'][0]\n",
    "#     ts_config_id = topic_config['time_slots'][0]\n",
    "#     ts_config = settings.APPLICATION_MC.TIME_SLOTS[ts_config_id]\n",
    "    prop_config = properties[prop]\n",
    "\n",
    "    observation_provider_name = f\"{Observation.__module__}.{Observation.__name__}\"\n",
    "    process_name_id = prop_config['observation_providers'][observation_provider_name][\"process\"]\n",
    "    process = Process.objects.get(name_id=process_name_id)\n",
    "\n",
    "    prop_item = Property.objects.get(name_id=prop)\n",
    "\n",
    "    pt_range, day_from, day_to = parse_date_range(str(phenomenon_date_from), str(phenomenon_date_to))\n",
    "\n",
    "    pt_range_z = DateTimeTZRange(\n",
    "        pt_range.lower.replace(tzinfo=UTC_P0100),\n",
    "        pt_range.upper.replace(tzinfo=UTC_P0100)\n",
    "    )\n",
    "\n",
    "#     zero = parse_datetime(ts_config['zero'])\n",
    "#     frequency = ts_config['frequency']\n",
    "#     range_from = ts_config['range_from']\n",
    "#     range_to = ts_config['range_to']\n",
    "\n",
    "#     t = TimeSeries(\n",
    "#         zero=zero,\n",
    "#         frequency=frequency,\n",
    "#         range_from=range_from,\n",
    "#         range_to=range_to\n",
    "#     )\n",
    "    t = TimeSlots.objects.get(name_id=ts_id)\n",
    "    \n",
    "    zero = t.zero\n",
    "#     t.full_clean()\n",
    "#     t.clean()\n",
    "    \n",
    "    nn_feature_ranges = get_not_null_ranges(\n",
    "#         features=[item],\n",
    "        features=[feature],\n",
    "        props=[prop],\n",
    "        topic_config=topic_config,\n",
    "        observation_provider_name=observation_provider_name,\n",
    "        provider_model=provider_model,\n",
    "        pt_range_z=pt_range_z,\n",
    "        time_slots=t,\n",
    "    )\n",
    "    \n",
    "    data_range = get_feature_nn_from_list(\n",
    "        nn_feature_ranges,\n",
    "#         item,\n",
    "        feature,\n",
    "        prop_item.id,\n",
    "        process.id\n",
    "    )\n",
    "\n",
    "    feature_time_slots = get_empty_slots(t, data_range)\n",
    "    \n",
    "    get_observations_func = partial(\n",
    "        get_observations,\n",
    "        feature_time_slots,\n",
    "        prop_item,\n",
    "        provider_model,\n",
    "#         item,\n",
    "        feature,\n",
    "        process,\n",
    "        t)\n",
    "    \n",
    "    anoms = ad.get_timeseries(\n",
    "    #     phenomenon_time_range=data_range,\n",
    "        phenomenon_time_range=pt_range_z,\n",
    "        num_time_slots=len(feature_time_slots),\n",
    "        get_observations=get_observations_func,\n",
    "        detector_method=detector_method,\n",
    "        detector_params=detector_params,\n",
    "        shift=shift,\n",
    "        use_baseline=use_baseline,\n",
    "        extend_range=extend_range,\n",
    "    )\n",
    "    \n",
    "    anoms[\"feature_time_slots\"] = feature_time_slots\n",
    "\n",
    "    return anoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(indices, alpha, color, ax):\n",
    "    i=0\n",
    "    while i<len(indices):\n",
    "        ax.axvspan(indices[i]-0.5, indices[i]+0.5, facecolor=color, edgecolor='none', alpha=alpha)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['r', 'g', 'c', 'm', 'y', 'k']\n",
    "results = []\n",
    "\n",
    "def plot(detectors, hlt_detector):\n",
    "    results = detectors\n",
    "    fig, ax1 = plt.subplots(figsize=(20,7))\n",
    "    first_result = detectors[list(detectors.keys())[0]]\n",
    "    \n",
    "    ts = pd.DataFrame({\n",
    "        'values': [float(n) for n in first_result[\"property_values\"]]\n",
    "    }, index=[n.lower.strftime(\"%-d.%-m.%Y\") for n in first_result[\"feature_time_slots\"]])\n",
    "    \n",
    "    values_line = ts['values'].plot.line(ax=ax1, color='b')\n",
    "    ax1.set_ylabel('values', color='b')\n",
    "    ax1.tick_params('y', colors='b')\n",
    "    \n",
    "    lns = [values_line.get_lines()[0]]\n",
    "    \n",
    "    for i in range(len(detectors.keys())):\n",
    "        detector = list(detectors.keys())[i]\n",
    "        color = colors[i]\n",
    "        anomalies = detectors[detector][\"property_anomaly_rates\"]\n",
    "\n",
    "        ts = pd.DataFrame({\n",
    "            'anomalies': anomalies\n",
    "        })\n",
    "        \n",
    "        ax2 = ax1.twinx()\n",
    "        anomalies_line = ts['anomalies'].plot.line(ax=ax2, color=color, label=detector)\n",
    "        lns.append(anomalies_line.get_lines()[0])\n",
    "        ax2.tick_params('y', colors=color)\n",
    "        \n",
    "        if detector == hlt_detector:\n",
    "            sev = detectors[detector][\"property_anomaly_severities\"]\n",
    "            for s in sev.keys():\n",
    "                highlight(ts[ts['anomalies'] > sev[s]].index, s*0.006, color, ax2)\n",
    "            \n",
    "\n",
    "    labs = [ln.get_label() for ln in lns]\n",
    "    ax1.legend(lns, labs, loc=1)\n",
    "    \n",
    "    # baseName = f\"{baserange.lower.date()}..{baserange.upper.date()}\"\n",
    "    rangeName = f\"{first_result['phenomenon_time_range'].lower.date()}..{first_result['phenomenon_time_range'].upper.date()}\"\n",
    "    # plt.savefig(f\"graphs/{baseName}_{rangeName}_window-{str(window_size)}_prec-{str(detector_params['precision'])}.png\", format=\"png\")\n",
    "    # plt.savefig(f\"graphs/{rangeName}_window-{str(window_size)}_prec-{str(detector_params['precision'])}.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors = [\"bitmap_mod\", \"bitmap_mod_shift\", \"bitmap_detector\", \"default_detector\", \"derivative_detector\", \"exp_avg_detector\", \"absolute_threshold\", \"diff_percent_threshold\", \"sign_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_bitmap_mod(feature, start_date, end_date, detector_params):\n",
    "    return detect_anomalies(start_date, end_date, \"bitmap_mod\", shift=False, feature=feature, detector_params=detector_params)\n",
    "def val_bitmap_mod_shift(feature, start_date, end_date, detector_params):\n",
    "    return detect_anomalies(start_date, end_date, \"bitmap_mod_shift\", feature=feature, detector_params=detector_params)\n",
    "def val_bitmap_detector(feature, start_date, end_date, detector_params):\n",
    "    return detect_anomalies(start_date, end_date, \"bitmap_detector\", feature=feature, detector_params=detector_params)\n",
    "def val_default_detector(feature, start_date, end_date, detector_params):\n",
    "    return detect_anomalies(start_date, end_date, \"default_detector\", feature=feature, detector_params={}, use_baseline=False, extend_range=False, shift=False)\n",
    "def val_derivative_detector(feature, start_date, end_date, detector_params):\n",
    "    return detect_anomalies(start_date, end_date, \"derivative_detector\", feature=feature, detector_params={}, use_baseline=False, extend_range=False, shift=False)\n",
    "def val_exp_avg_detector(feature, start_date, end_date, detector_params):\n",
    "    return detect_anomalies(start_date, end_date, \"exp_avg_detector\", feature=feature, detector_params={}, use_baseline=False, extend_range=False, shift=False)\n",
    "def val_absolute_threshold(feature, start_date, end_date, detector_params):\n",
    "    return detect_anomalies(t_from, t_to, \"absolute_threshold\", feature=feature, detector_params={}, use_baseline=False, extend_range=False, shift=False)\n",
    "def val_diff_percent_threshold(feature, start_date, end_date, detector_params):\n",
    "    return detect_anomalies(t_from, t_to, \"diff_percent_threshold\", feature=feature, detector_params={}, use_baseline=False, extend_range=False, shift=False)\n",
    "def val_sign_test(feature, start_date, end_date, detector_params):\n",
    "    return detect_anomalies(t_from, t_to, \"sign_test\", feature=feature, detector_params={}, use_baseline=False, extend_range=False, shift=False)\n",
    "\n",
    "def plot_anomalies(feature, start_date, end_date, precision, window_size, chunk_size, hlt_detector, bitmap_mod, bitmap_mod_shift, bitmap_detector, default_detector, derivative_detector, exp_avg_detector):\n",
    "    args = [feature, start_date, end_date, {\n",
    "        \"precision\": precision,\n",
    "        \"lag_window_size\": window_size,\n",
    "        \"future_window_size\": window_size,\n",
    "        \"chunk_size\": chunk_size\n",
    "    }]\n",
    "    anomalies = {}\n",
    "    \n",
    "    if bitmap_mod:\n",
    "        anomalies[\"bitmap_mod\"] = val_bitmap_mod(*args)\n",
    "    if bitmap_mod_shift:\n",
    "        anomalies[\"bitmap_mod_shift\"] = val_bitmap_mod_shift(*args)\n",
    "    if bitmap_detector:\n",
    "        anomalies[\"bitmap_detector\"] = val_bitmap_detector(*args)\n",
    "    if default_detector:\n",
    "        anomalies[\"default_detector\"] = val_default_detector(*args)\n",
    "    if derivative_detector:\n",
    "        anomalies[\"derivative_detector\"] = val_derivative_detector(*args)\n",
    "    if exp_avg_detector:\n",
    "        anomalies[\"exp_avg_detector\"] = val_exp_avg_detector(*args)\n",
    "            \n",
    "#     if absolute_threshold:\n",
    "#         anomalies[\"absolute_threshold\"] = val_absolute_threshold(*args)\n",
    "#     if diff_percent_threshold:\n",
    "#         anomalies[\"diff_percent_threshold\"] = val_diff_percent_threshold(*args)\n",
    "#     if sign_test:\n",
    "#         anomalies[\"sign_test\"] = val_sign_test(*args)\n",
    "        \n",
    "        \n",
    "    if len(anomalies.keys()) > 1:\n",
    "        i = 0\n",
    "        while hlt_detector not in anomalies.keys():\n",
    "            hlt_detector = detectors[i]\n",
    "            i += 1\n",
    "        plot(anomalies, hlt_detector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fd468eb9114b969c2b56c463999ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='feature', options=(<SamplingFeature: Brno, botanical garden PřF MU…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_anomalies(feature, start_date, end_date, precision, window_size, chunk_size, hlt_detector, bitmap_mod, bitmap_mod_shift, bitmap_detector, default_detector, derivative_detector, exp_avg_detector)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_from = \"2019-01-01\"\n",
    "t_to = \"2019-03-30\"\n",
    "interact_manual(plot_anomalies,\n",
    "                feature=features,\n",
    "                start_date=widgets.DatePicker(value=pd.to_datetime(t_from).date(), description=\"Start date\"),\n",
    "                end_date=widgets.DatePicker(value=pd.to_datetime(t_to).date(), description=\"End date\"),\n",
    "                bitmap_mod=widgets.Checkbox(value=True,description=\"Bitmap mod\"),\n",
    "                bitmap_mod_shift=widgets.Checkbox(value=True,description=\"Bitmap mod shift\"),\n",
    "                bitmap_detector=widgets.Checkbox(value=True,description=\"LinkedIn bitmap\"),\n",
    "                default_detector=widgets.Checkbox(value=False,description=\"Default\"),\n",
    "                derivative_detector=widgets.Checkbox(value=False,description=\"Derivative\"),\n",
    "                exp_avg_detector=widgets.Checkbox(value=False,description=\"Exponential average\"),\n",
    "                #          absolute_threshold=widgets.Checkbox(value=False,description=\"Absolute threshold\"),\n",
    "                #          diff_percent_threshold=widgets.Checkbox(value=False,description=\"Diff Percent\"),\n",
    "                #          sign_test=widgets.Checkbox(value=False,description=\"Sign test\"),\n",
    "                precision=widgets.IntSlider(value=6, min=2, max=16, step=1, description=\"Precision\"),\n",
    "                window_size=widgets.BoundedIntText(value=96, min=16, max=256, step=1, description=\"Window size\"),\n",
    "                chunk_size=widgets.IntSlider(value=2, min=2, max=16, step=1, description=\"Chunk size\"),\n",
    "                hlt_detector=detectors,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
