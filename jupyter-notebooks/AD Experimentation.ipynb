{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import django\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps.processing.ala.models import SamplingFeature, Observation\n",
    "from apps.processing.ala.util import util\n",
    "\n",
    "from importlib import import_module\n",
    "from django.conf import settings\n",
    "from apps.common.models import Process, Property\n",
    "\n",
    "import pytz\n",
    "import time\n",
    "from psycopg2.extras import DateTimeTZRange\n",
    "from django.utils.dateparse import parse_datetime\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "# from luminol.anomaly_detector import AnomalyDetector\n",
    "import luminol.anomaly_detector as lad\n",
    "\n",
    "from apps.utils.time import UTC_P0100\n",
    "from apps.common.util.util import generate_intervals\n",
    "# from apps.ad.anomaly_detection import *\n",
    "import apps.ad.anomaly_detection as ad\n",
    "\n",
    "feature = SamplingFeature.objects.get(id_by_provider='11359201')\n",
    "observed_property = Property.objects.get(name_id='air_temperature')\n",
    "\n",
    "from apps.mc.api.views import get_observations, parse_date_range, get_empty_slots\n",
    "\n",
    "from apps.processing.ala.models import SamplingFeature, Observation\n",
    "from apps.common.models import Process, Property, TimeSeries\n",
    "from psycopg2.extras import DateTimeTZRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"drought\"\n",
    "prop = \"air_temperature\"\n",
    "phenomenon_date_from = pd.to_datetime(\"2019-01-01\")\n",
    "phenomenon_date_to = pd.to_datetime(\"2019-01-30\")\n",
    "provider_model = Observation\n",
    "\n",
    "def detect_anomalies(\n",
    "    phenomenon_date_from = phenomenon_date_from,\n",
    "    phenomenon_date_to = phenomenon_date_to,\n",
    "    detector_method='bitmap_mod',\n",
    "    use_baseline=True,\n",
    "    shift=True,\n",
    "    extend_range=True,\n",
    "    detector_params={\n",
    "        \"precision\": 6,\n",
    "        \"lag_window_size\": 96,\n",
    "        \"future_window_size\": 96,\n",
    "        \"chunk_size\": 2\n",
    "    },\n",
    "    topic = topic,\n",
    "    prop = prop,\n",
    "    provider_model = provider_model,\n",
    "):\n",
    "    reload(ad)\n",
    "    reload(lad)\n",
    "\n",
    "    item = provider_model._meta.get_field('feature_of_interest').remote_field.model.objects.all()[5]\n",
    "\n",
    "    observation_provider_name = f\"{provider_model.__module__}.{provider_model.__name__}\"\n",
    "    topic_config = settings.APPLICATION_MC.TOPICS.get(topic)\n",
    "\n",
    "    properties = topic_config['properties']\n",
    "    ts_config = topic_config['time_series']\n",
    "    prop_config = properties[prop]\n",
    "\n",
    "    observation_provider_name = f\"{Observation.__module__}.{Observation.__name__}\"\n",
    "    process_name_id = prop_config['observation_providers'][observation_provider_name][\"process\"]\n",
    "    process = Process.objects.get(name_id=process_name_id)\n",
    "\n",
    "    prop_item = Property.objects.get(name_id=prop)\n",
    "\n",
    "    pt_range, day_from, day_to = parse_date_range(str(phenomenon_date_from), str(phenomenon_date_to))\n",
    "\n",
    "    pt_range_z = DateTimeTZRange(\n",
    "        pt_range.lower.replace(tzinfo=UTC_P0100),\n",
    "        pt_range.upper.replace(tzinfo=UTC_P0100)\n",
    "    )\n",
    "\n",
    "    zero = parse_datetime(ts_config['zero'])\n",
    "    frequency = ts_config['frequency']\n",
    "    range_from = ts_config['range_from']\n",
    "    range_to = ts_config['range_to']\n",
    "\n",
    "    t = TimeSeries(\n",
    "        zero=zero,\n",
    "        frequency=frequency,\n",
    "        range_from=range_from,\n",
    "        range_to=range_to\n",
    "    )\n",
    "    t.full_clean()\n",
    "    t.clean()\n",
    "\n",
    "    feature_time_slots = get_empty_slots(t, pt_range_z)\n",
    "\n",
    "    get_observations_func = partial(\n",
    "        get_observations,\n",
    "        feature_time_slots,\n",
    "        prop_item,\n",
    "        provider_model,\n",
    "        item,\n",
    "        process,\n",
    "        t)\n",
    "\n",
    "    return ad.get_timeseries(\n",
    "    #     phenomenon_time_range=data_range,\n",
    "        phenomenon_time_range=pt_range_z,\n",
    "        num_time_slots=len(feature_time_slots),\n",
    "        get_observations=get_observations_func,\n",
    "        detector_method=detector_method,\n",
    "        detector_params=detector_params,\n",
    "        shift=shift,\n",
    "        use_baseline=use_baseline,\n",
    "        extend_range=extend_range,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['r', 'g', 'c', 'm', 'y', 'k']\n",
    "\n",
    "def plot(detectors):\n",
    "    fig, ax1 = plt.subplots(figsize=(20,7))\n",
    "    first_result = detectors[list(detectors.keys())[0]]\n",
    "    \n",
    "    ts = pd.DataFrame({\n",
    "        'values': [float(n) for n in first_result[\"property_values\"]]\n",
    "    })\n",
    "    \n",
    "    values_line = ts['values'].plot.line(ax=ax1, color='b')\n",
    "    ax1.set_ylabel('values', color='b')\n",
    "    ax1.tick_params('y', colors='b')\n",
    "    \n",
    "    lns = [values_line.get_lines()[0]]\n",
    "    \n",
    "    for i in range(len(detectors.keys())):\n",
    "        detector = list(detectors.keys())[i]\n",
    "        color = colors[i]\n",
    "        anomalies = detectors[detector][\"property_anomaly_rates\"]\n",
    "\n",
    "        ts = pd.DataFrame({\n",
    "            'anomalies': anomalies\n",
    "        })\n",
    "        \n",
    "        ax2 = ax1.twinx()\n",
    "        anomalies_line = ts['anomalies'].plot.line(ax=ax2, color=color, label=detector)\n",
    "        lns.append(anomalies_line.get_lines()[0])\n",
    "#         if i == 1:\n",
    "#             ax2.set_ylabel('anomalies', color='k')\n",
    "        ax2.tick_params('y', colors=color)\n",
    "\n",
    "    labs = [ln.get_label() for ln in lns]\n",
    "    ax1.legend(lns, labs, loc=1)\n",
    "    \n",
    "    # baseName = f\"{baserange.lower.date()}..{baserange.upper.date()}\"\n",
    "    rangeName = f\"{first_result['phenomenon_time_range'].lower.date()}..{first_result['phenomenon_time_range'].upper.date()}\"\n",
    "    # plt.savefig(f\"graphs/{baseName}_{rangeName}_window-{str(window_size)}_prec-{str(detector_params['precision'])}.png\", format=\"png\")\n",
    "    # plt.savefig(f\"graphs/{rangeName}_window-{str(window_size)}_prec-{str(detector_params['precision'])}.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_anomalies(start_date, end_date):\n",
    "#     start_date = start_date.date()\n",
    "#     end_date = end_date.date()\n",
    "    anomalies = {\n",
    "        'Bitmap mod': detect_anomalies(start_date, end_date, \"bitmap_mod\", shift=False),\n",
    "        'Bitmap mod shift': detect_anomalies(start_date, end_date, \"bitmap_mod_shift\"),\n",
    "        'LinkedIn bitmap': detect_anomalies(start_date, end_date, \"bitmap_detector\"),\n",
    "        'Default': detect_anomalies(start_date, end_date, \"default_detector\", detector_params={}, use_baseline=False, extend_range=False, shift=False),\n",
    "        'Derivative': detect_anomalies(start_date, end_date, \"derivative_detector\", detector_params={}, use_baseline=False, extend_range=False, shift=False),\n",
    "        'Exponential average': detect_anomalies(start_date, end_date, \"exp_avg_detector\", detector_params={}, use_baseline=False, extend_range=False, shift=False),\n",
    "    #     'Absolute threshold': detect_anomalies(t_from, t_to, \"absolute_threshold\", detector_params={}, use_baseline=False, extend_range=False, shift=False),\n",
    "    #     'Diff Percent': detect_anomalies(t_from, t_to, \"diff_percent_threshold\", detector_params={}, use_baseline=False, extend_range=False, shift=False),\n",
    "    #     'Sign test': detect_anomalies(t_from, t_to, \"sign_test\", detector_params={}, use_baseline=False, extend_range=False, shift=False),\n",
    "    }\n",
    "\n",
    "    plot(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a27750d98d4785b341fbc13b2ff029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(DatePicker(value=datetime.date(2019, 1, 1), description='start_date'), DatePicker(value=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_anomalies(start_date, end_date)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_from = \"2019-01-01\"\n",
    "t_to = \"2019-01-30\"\n",
    "\n",
    "interact(plot_anomalies,\n",
    "     start_date=widgets.DatePicker(value=pd.to_datetime(t_from).date()),\n",
    "     end_date=widgets.DatePicker(value=pd.to_datetime(t_to).date()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
